{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68084f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f50ba36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# URL HTML com as duas abas publicadas\n",
    "URL_HTML = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vSa06AfYC_ufn2vqTsYZkeyX7QvNwYH2gdH8VPcZOCS8_pyOJzTOtU3tufy_OL5sWhVvW_qm3mBpWJr/pubhtml\"\n",
    "\n",
    "OUT_DIR = Path(\"outputs\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def parse_num_pt(x):\n",
    "    \"\"\"Converte '1.234,56' -> 1234.56 mantendo NaN quando vazio.\"\"\"\n",
    "    if pd.isna(x): \n",
    "        return np.nan\n",
    "    if isinstance(x, (int, float)):\n",
    "        return float(x)\n",
    "    s = str(x).strip()\n",
    "    if not s:\n",
    "        return np.nan\n",
    "    s = s.replace('.', '').replace(',', '.')\n",
    "    try:\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def clean_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Remove colunas 'Unnamed', linhas-cabeçalho duplicadas e normaliza nomes.\"\"\"\n",
    "    df = df.loc[:, ~df.columns.astype(str).str.startswith(\"Unnamed\")]\n",
    "    # remove linhas que repetem o cabeçalho\n",
    "    if len(df):\n",
    "        mask = df.astype(str).apply(lambda s: (list(s.values) == list(df.columns.astype(str))), axis=1)\n",
    "        if mask.any():\n",
    "            df = df.loc[~mask]\n",
    "    df.columns = [re.sub(r'\\s+', ' ', c).strip() for c in df.columns.astype(str)]\n",
    "    return df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a69b69a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'html5lib'.  Use pip or conda to install html5lib.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\hmatr\\anaconda3\\Lib\\site-packages\\pandas\\compat\\_optional.py:135\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 135\u001b[0m     module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(name)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\hmatr\\anaconda3\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1140\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'html5lib'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Lê todas as tabelas presentes na página HTML.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Usamos decimal=',' e thousands='.' para ajudar a interpretar números europeus.\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m tables \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_html(URL_HTML, flavor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbs4\u001b[39m\u001b[38;5;124m\"\u001b[39m, displayed_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, decimal\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, thousands\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForam lidas \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(tables)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tabelas do HTML.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tables):\n",
      "File \u001b[1;32mc:\\Users\\hmatr\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:1240\u001b[0m, in \u001b[0;36mread_html\u001b[1;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend, storage_options)\u001b[0m\n\u001b[0;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m   1225\u001b[0m     [\n\u001b[0;32m   1226\u001b[0m         is_file_like(io),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1230\u001b[0m     ]\n\u001b[0;32m   1231\u001b[0m ):\n\u001b[0;32m   1232\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing literal html to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread_html\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1234\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. To read from a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1237\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1238\u001b[0m     )\n\u001b[1;32m-> 1240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parse(\n\u001b[0;32m   1241\u001b[0m     flavor\u001b[38;5;241m=\u001b[39mflavor,\n\u001b[0;32m   1242\u001b[0m     io\u001b[38;5;241m=\u001b[39mio,\n\u001b[0;32m   1243\u001b[0m     match\u001b[38;5;241m=\u001b[39mmatch,\n\u001b[0;32m   1244\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   1245\u001b[0m     index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m   1246\u001b[0m     skiprows\u001b[38;5;241m=\u001b[39mskiprows,\n\u001b[0;32m   1247\u001b[0m     parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[0;32m   1248\u001b[0m     thousands\u001b[38;5;241m=\u001b[39mthousands,\n\u001b[0;32m   1249\u001b[0m     attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1250\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   1251\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   1252\u001b[0m     converters\u001b[38;5;241m=\u001b[39mconverters,\n\u001b[0;32m   1253\u001b[0m     na_values\u001b[38;5;241m=\u001b[39mna_values,\n\u001b[0;32m   1254\u001b[0m     keep_default_na\u001b[38;5;241m=\u001b[39mkeep_default_na,\n\u001b[0;32m   1255\u001b[0m     displayed_only\u001b[38;5;241m=\u001b[39mdisplayed_only,\n\u001b[0;32m   1256\u001b[0m     extract_links\u001b[38;5;241m=\u001b[39mextract_links,\n\u001b[0;32m   1257\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1258\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   1259\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\hmatr\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:971\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    969\u001b[0m retained \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m flav \u001b[38;5;129;01min\u001b[39;00m flavor:\n\u001b[1;32m--> 971\u001b[0m     parser \u001b[38;5;241m=\u001b[39m _parser_dispatch(flav)\n\u001b[0;32m    972\u001b[0m     p \u001b[38;5;241m=\u001b[39m parser(\n\u001b[0;32m    973\u001b[0m         io,\n\u001b[0;32m    974\u001b[0m         compiled_match,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    979\u001b[0m         storage_options,\n\u001b[0;32m    980\u001b[0m     )\n\u001b[0;32m    982\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\hmatr\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:915\u001b[0m, in \u001b[0;36m_parser_dispatch\u001b[1;34m(flavor)\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(flavor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid flavor, valid flavors are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_parsers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    912\u001b[0m     )\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flavor \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbs4\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml5lib\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 915\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml5lib\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    916\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbs4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    917\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\hmatr\\anaconda3\\Lib\\site-packages\\pandas\\compat\\_optional.py:138\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 138\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'html5lib'.  Use pip or conda to install html5lib."
     ]
    }
   ],
   "source": [
    "# Lê todas as tabelas presentes na página HTML.\n",
    "# Usamos decimal=',' e thousands='.' para ajudar a interpretar números europeus.\n",
    "tables = pd.read_html(URL_HTML, flavor=\"bs4\", displayed_only=True, decimal=',', thousands='.')\n",
    "\n",
    "print(f\"Foram lidas {len(tables)} tabelas do HTML.\\n\")\n",
    "for i, t in enumerate(tables):\n",
    "    print(f\"[{i}] shape={t.shape} | colunas={list(t.columns)}\")\n",
    "\n",
    "# Assinaturas esperadas (podem variar levemente; ajuste se mudar seu cabeçalho)\n",
    "cols_resumo_expect = {\"Semana\", \"Canal\", \"Pães\", \"Receita (€)\"}\n",
    "cols_pedidos_expect = {\n",
    "    \"Data\",\"Semana\",\"Cliente\",\"Região\",\"Quantidade (pães)\",\n",
    "    \"Tipo (Fresco/MAP)\",\"Canal\",\"Valor Unitário (€)\",\"Valor Total (€)\",\"Status (Pago/Deve)\"\n",
    "}\n",
    "\n",
    "def score(df_cols, expected):\n",
    "    cset = set(map(str, df_cols))\n",
    "    return len(cset & expected), len(expected - cset)\n",
    "\n",
    "idx_resumo = idx_pedidos = None\n",
    "best_r = (-1, 999)\n",
    "best_p = (-1, 999)\n",
    "\n",
    "for i, t in enumerate(tables):\n",
    "    sr = score(t.columns, cols_resumo_expect)\n",
    "    sp = score(t.columns, cols_pedidos_expect)\n",
    "    if sr > best_r and sr[0] >= 3:\n",
    "        best_r = sr; idx_resumo = i\n",
    "    if sp > best_p and sp[0] >= 6:\n",
    "        best_p = sp; idx_pedidos = i\n",
    "\n",
    "print(\"\\nProvável índice do RESUMO:\", idx_resumo, \" | score:\", best_r)\n",
    "print(\"Provável índice dos PEDIDOS:\", idx_pedidos, \" | score:\", best_p)\n",
    "\n",
    "if idx_resumo is None or idx_pedidos is None:\n",
    "    raise ValueError(\"Não foi possível identificar as tabelas de Resumo/Pedidos no HTML. Revise cabeçalhos/assinaturas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2584e4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resumo = clean_df(tables[idx_resumo].copy())\n",
    "df_pedidos = clean_df(tables[idx_pedidos].copy())\n",
    "\n",
    "# Conversões numéricas\n",
    "if 'Receita (€)' in df_resumo.columns:\n",
    "    df_resumo['Receita (€)'] = df_resumo['Receita (€)'].apply(parse_num_pt)\n",
    "if 'Pães' in df_resumo.columns:\n",
    "    df_resumo['Pães'] = pd.to_numeric(df_resumo['Pães'], errors='coerce').astype('Int64')\n",
    "\n",
    "for col in ['Valor Unitário (€)', 'Valor Total (€)']:\n",
    "    if col in df_pedidos.columns:\n",
    "        df_pedidos[col] = df_pedidos[col].apply(parse_num_pt)\n",
    "if 'Quantidade (pães)' in df_pedidos.columns:\n",
    "    df_pedidos['Quantidade (pães)'] = pd.to_numeric(df_pedidos['Quantidade (pães)'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Normaliza tipo e flag ATM\n",
    "tipo_col = 'Tipo (Fresco/MAP)'\n",
    "if tipo_col in df_pedidos.columns:\n",
    "    df_pedidos[tipo_col] = df_pedidos[tipo_col].astype(str).str.strip()\n",
    "else:\n",
    "    df_pedidos[tipo_col] = 'Fresco'\n",
    "df_pedidos['is_atm'] = df_pedidos[tipo_col].str.upper().eq('ATM')\n",
    "\n",
    "# Totais rápidos\n",
    "total_paes = int(df_pedidos['Quantidade (pães)'].sum())\n",
    "total_receita = float(df_pedidos['Valor Total (€)'].sum())\n",
    "print(\"=== Totais (Pedidos) ===\")\n",
    "print(f\"Pães: {total_paes}\")\n",
    "print(f\"Receita (€): {round(total_receita,2)}\")\n",
    "\n",
    "display(df_resumo.head())\n",
    "display(df_pedidos.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ebfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Premissas (Word) ----------------\n",
    "# Ingredientes + embalagem (saco+etiqueta) por pão\n",
    "CUSTO_INGREDIENTES = 0.05       # €/pão\n",
    "EMBALAGEM_SACO_10  = 0.17       # €/saco com 10 pães\n",
    "ETIQUETA_SACO_10   = 0.02       # €/saco com 10 pães\n",
    "EMBALAGEM_POR_PAO  = (EMBALAGEM_SACO_10 + ETIQUETA_SACO_10)/10.0\n",
    "COGS_BASE          = CUSTO_INGREDIENTES + EMBALAGEM_POR_PAO   # €/pão\n",
    "\n",
    "# Logística / comissão\n",
    "COMISSAO_ANINHA  = 0.20         # €/pão (D2C entrega)\n",
    "NACEX_ENVIO_10KG = 5.50         # € por envio (10kg tier)\n",
    "CUSTO_CAIXA      = 0.60         # € por caixa econômica\n",
    "PAES_POR_CAIXA   = 70           # ~7 sacos de 10 pães\n",
    "NACEX_POR_PAO    = (NACEX_ENVIO_10KG + CUSTO_CAIXA)/PAES_POR_CAIXA  # €/pão\n",
    "\n",
    "# MAP (ATM) — custo por pão em dois cenários\n",
    "MAP_COST_LOW  = 0.012           # €/pão (alto volume)\n",
    "MAP_COST_HIGH = 0.050           # €/pão (baixo volume)\n",
    "\n",
    "# Custos fixos mensais (aluguel, utilidades, salários)\n",
    "CUSTOS_FIXOS_MES = 2700.0       # €\n",
    "\n",
    "# Fallback de preços por canal (usamos a mediana observada se existir)\n",
    "FALLBACK_PRECOS = {\n",
    "    'Aninha': 0.70,\n",
    "    'Recolha': 0.50,\n",
    "    'Boa Turma': 0.40,\n",
    "    'NACEX': 0.45,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1552bb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_precos_por_canal(df):\n",
    "    \"\"\"Mediana do preço por canal vinda do próprio dataset; se faltar, usa fallback.\"\"\"\n",
    "    precos = df.groupby('Canal')['Valor Unitário (€)'].median().to_dict()\n",
    "    for k,v in FALLBACK_PRECOS.items():\n",
    "        precos.setdefault(k, v)\n",
    "    return precos\n",
    "\n",
    "def cogs_por_pao(canal, is_atm: bool, scenario='low'):\n",
    "    \"\"\"COGS = base + adders (comissão/entrega) + MAP (se ATM).\"\"\"\n",
    "    add = 0.0\n",
    "    if canal == 'Aninha':\n",
    "        add += COMISSAO_ANINHA\n",
    "    if canal == 'NACEX':\n",
    "        add += NACEX_POR_PAO\n",
    "    map_cost = 0.0\n",
    "    if is_atm:\n",
    "        map_cost = MAP_COST_LOW if scenario=='low' else MAP_COST_HIGH\n",
    "    return COGS_BASE + add + map_cost\n",
    "\n",
    "def unit_economics_tabela(df, precos_por_canal):\n",
    "    rows = []\n",
    "    canais = sorted(df['Canal'].dropna().unique())\n",
    "    for ch in canais:\n",
    "        preco = precos_por_canal.get(ch, np.nan)\n",
    "        for is_atm in [False, True]:\n",
    "            label = f\"{ch} - {'ATM' if is_atm else 'Fresco'}\"\n",
    "            cogs_l = cogs_por_pao(ch, is_atm, 'low')\n",
    "            cogs_h = cogs_por_pao(ch, is_atm, 'high')\n",
    "            marg_l = preco - cogs_l if pd.notna(preco) else np.nan\n",
    "            marg_h = preco - cogs_h if pd.notna(preco) else np.nan\n",
    "            rows.append({\n",
    "                'Canal/Tipo': label,\n",
    "                'Preço (€)': round(preco,3) if pd.notna(preco) else np.nan,\n",
    "                'COGS baixo (€)': round(cogs_l,3),\n",
    "                'COGS alto (€)': round(cogs_h,3),\n",
    "                'Margem baixo (€)': round(marg_l,3) if pd.notna(marg_l) else np.nan,\n",
    "                'Margem alto (€)': round(marg_h,3) if pd.notna(marg_h) else np.nan,\n",
    "                'Margem baixo (%)': round(100*marg_l/preco,1) if preco else np.nan,\n",
    "                'Margem alto (%)': round(100*marg_h/preco,1) if preco else np.nan,\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def consolidar_contribuicao(df):\n",
    "    \"\"\"Calcula contribuição por canal em dois cenários (MAP baixo/alto) e aloca fixos por volume.\"\"\"\n",
    "    df = df.copy()\n",
    "    for sc in ['low','high']:\n",
    "        df[f'COGS/pão {sc}'] = df.apply(lambda r: cogs_por_pao(r['Canal'], bool(r['is_atm']), sc), axis=1)\n",
    "        df[f'Margem/pão {sc}'] = df['Valor Unitário (€)'] - df[f'COGS/pão {sc}']\n",
    "        df[f'Contribuição {sc}'] = df[f'Margem/pão {sc}'] * df['Quantidade (pães)']\n",
    "    contri = (df.groupby('Canal', as_index=False)\n",
    "                .agg(paes=('Quantidade (pães)','sum'),\n",
    "                     receita=('Valor Total (€)','sum'),\n",
    "                     contrib_baixa=('Contribuição low','sum'),\n",
    "                     contrib_alta=('Contribuição high','sum')))\n",
    "    total_p = contri['paes'].sum()\n",
    "    contri['FixedCost alloc (€)'] = CUSTOS_FIXOS_MES * (contri['paes']/total_p) if total_p else 0.0\n",
    "    contri['Lucro op (baixo) €'] = contri['contrib_baixa'] - contri['FixedCost alloc (€)']\n",
    "    contri['Lucro op (alto)  €'] = contri['contrib_alta']  - contri['FixedCost alloc (€)']\n",
    "    return contri\n",
    "\n",
    "def calcular_break_even(contri_df):\n",
    "    \"\"\"CM e Break-even mensal:\n",
    "       CM = Contribuição total / Pães totais\n",
    "       BE (pães/mês) = Custos Fixos / CM\n",
    "    \"\"\"\n",
    "    total_contrib_low  = contri_df['contrib_baixa'].sum()\n",
    "    total_contrib_high = contri_df['contrib_alta'].sum()\n",
    "    total_paes         = contri_df['paes'].sum()\n",
    "    cm_low  = total_contrib_low / total_paes if total_paes else np.nan\n",
    "    cm_high = total_contrib_high / total_paes if total_paes else np.nan\n",
    "    be_low  = CUSTOS_FIXOS_MES / cm_low if cm_low else np.nan\n",
    "    be_high = CUSTOS_FIXOS_MES / cm_high if cm_high else np.nan\n",
    "    return cm_low, cm_high, be_low, be_high\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561c246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "precos_canais = obter_precos_por_canal(df_pedidos)\n",
    "\n",
    "unit_df = unit_economics_tabela(df_pedidos, precos_canais)\n",
    "display(unit_df)\n",
    "\n",
    "contri_df = consolidar_contribuicao(df_pedidos)\n",
    "display(contri_df.round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485e1f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_low, cm_high, be_low, be_high = calcular_break_even(contri_df)\n",
    "\n",
    "print(\"=== CM e Break-even (mês) ===\")\n",
    "print(f\"CM €/pão (MAP baixo): {None if pd.isna(cm_low) else round(cm_low,3)}\")\n",
    "print(f\"CM €/pão (MAP alto):  {None if pd.isna(cm_high) else round(cm_high,3)}\")\n",
    "print(f\"Break-even pães/mês (MAP baixo): {None if pd.isna(be_low) else int(round(be_low,0))}\")\n",
    "print(f\"Break-even pães/mês (MAP alto):  {None if pd.isna(be_high) else int(round(be_high,0))}\")\n",
    "\n",
    "# Gráfico — mix por canal (pães)\n",
    "mix = (df_pedidos.groupby('Canal', as_index=False)\n",
    "       .agg(paes=('Quantidade (pães)','sum'),\n",
    "            receita=('Valor Total (€)','sum'))\n",
    "       .sort_values('paes', ascending=False))\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.bar(mix['Canal'], mix['paes'])\n",
    "plt.title('Mix de Pães por Canal')\n",
    "plt.xlabel('Canal'); plt.ylabel('Pães')\n",
    "plt.xticks(rotation=25)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Gráfico — evolução semanal (pães)\n",
    "sem = (df_pedidos.groupby('Semana', as_index=False)\n",
    "       .agg(paes=('Quantidade (pães)','sum'),\n",
    "            receita=('Valor Total (€)','sum'))\n",
    "       .sort_values('Semana'))\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(sem['Semana'], sem['paes'], marker='o')\n",
    "plt.title('Evolução Semanal de Pães')\n",
    "plt.xlabel('Semana'); plt.ylabel('Pães')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ad1ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_path   = OUT_DIR / \"unit_economics_canais.csv\"\n",
    "contri_path = OUT_DIR / \"contribuicao_canais.csv\"\n",
    "mix_path    = OUT_DIR / \"mix_canal.csv\"\n",
    "sem_path    = OUT_DIR / \"evolucao_semanal.csv\"\n",
    "\n",
    "unit_df.to_csv(unit_path, index=False, encoding=\"utf-8-sig\")\n",
    "contri_df.round(2).to_csv(contri_path, index=False, encoding=\"utf-8-sig\")\n",
    "mix.round(2).to_csv(mix_path, index=False, encoding=\"utf-8-sig\")\n",
    "sem.round(2).to_csv(sem_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"Arquivos exportados em:\", OUT_DIR.resolve())\n",
    "for p in [unit_path, contri_path, mix_path, sem_path]:\n",
    "    print(\"-\", p.name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
